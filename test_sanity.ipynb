{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7624 images belonging to 53 classes.\n",
      "Found 265 images belonging to 53 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "base_dir = \"kaggle_cards_dataset\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir   = os.path.join(base_dir, \"valid\")\n",
    "test_dir  = os.path.join(base_dir, \"test\")\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.3,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.4,\n",
    "      zoom_range=0.6,\n",
    "      horizontal_flip=False,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'categorical', \n",
    "                                                    target_size = (150, 150))\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_generator = validation_datagen.flow_from_directory(val_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'categorical', \n",
    "                                                    target_size = (150, 150))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "(train_images, train_labels), (dev_images, dev_labels) = mnist.load_data()\n",
    "\n",
    "n_val = int(len(dev_images) / 2)\n",
    "\n",
    "val_images, val_labels = dev_images[:n_val], dev_labels[:n_val]\n",
    "test_images, test_labels = dev_images[n_val:], dev_labels[n_val:]\n",
    "\n",
    "import numpy as np\n",
    "train_images = tf.reshape(train_images, [-1, 28, 28, 1])\n",
    "val_images = tf.reshape(val_images, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "inputs = layers.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 986us/step - accuracy: 0.8271 - loss: 4.9025 - val_accuracy: 0.8908 - val_loss: 0.8241\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 875us/step - accuracy: 0.9272 - loss: 0.4783 - val_accuracy: 0.9326 - val_loss: 0.3618\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 896us/step - accuracy: 0.9439 - loss: 0.2946 - val_accuracy: 0.9346 - val_loss: 0.3699\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 882us/step - accuracy: 0.9528 - loss: 0.2596 - val_accuracy: 0.9424 - val_loss: 0.3574\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 852us/step - accuracy: 0.9570 - loss: 0.2476 - val_accuracy: 0.9350 - val_loss: 0.4137\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 961us/step - accuracy: 0.9601 - loss: 0.2397 - val_accuracy: 0.9412 - val_loss: 0.4261\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 854us/step - accuracy: 0.9603 - loss: 0.2479 - val_accuracy: 0.9452 - val_loss: 0.4410\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 841us/step - accuracy: 0.9612 - loss: 0.2320 - val_accuracy: 0.9344 - val_loss: 0.7530\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 811us/step - accuracy: 0.9635 - loss: 0.2426 - val_accuracy: 0.9440 - val_loss: 0.5302\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 920us/step - accuracy: 0.9633 - loss: 0.2347 - val_accuracy: 0.9404 - val_loss: 0.5537\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 872us/step - accuracy: 0.9630 - loss: 0.2342 - val_accuracy: 0.9426 - val_loss: 0.7547\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 820us/step - accuracy: 0.9619 - loss: 0.2450 - val_accuracy: 0.9474 - val_loss: 0.6882\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 865us/step - accuracy: 0.9642 - loss: 0.2287 - val_accuracy: 0.9438 - val_loss: 0.9957\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 896us/step - accuracy: 0.9657 - loss: 0.2405 - val_accuracy: 0.9452 - val_loss: 1.0144\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 887us/step - accuracy: 0.9646 - loss: 0.2654 - val_accuracy: 0.9282 - val_loss: 0.8542\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 929us/step - accuracy: 0.9645 - loss: 0.2778 - val_accuracy: 0.9422 - val_loss: 0.7255\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 862us/step - accuracy: 0.9629 - loss: 0.2596 - val_accuracy: 0.9376 - val_loss: 0.8042\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 863us/step - accuracy: 0.9675 - loss: 0.2306 - val_accuracy: 0.9372 - val_loss: 0.6545\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 956us/step - accuracy: 0.9637 - loss: 0.2599 - val_accuracy: 0.9366 - val_loss: 1.2838\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 997us/step - accuracy: 0.9657 - loss: 0.2935 - val_accuracy: 0.9398 - val_loss: 1.1558\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x=train_images, y=train_labels, validation_data=(val_images, val_labels), epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
